{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b406058",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  \n",
    "import os\n",
    "import torch.nn as nn \n",
    "\n",
    "import torch.nn.functional as F \n",
    "\n",
    "import torch.optim as optim \n",
    "\n",
    "from torch.utils.data import DataLoader \n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "class SIGNSDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform):      \n",
    "        self.filenames, self.labels = self.get_filenames(data_dir)\n",
    "        image = Image.open(self.filenames[0])\n",
    "        \n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "    \n",
    "    def get_filenames(self, data_dir):\n",
    "        filenames = []\n",
    "        labels = []\n",
    "        for class_folder in os.listdir(data_dir):\n",
    "            class_path = os.path.join(data_dir, class_folder)\n",
    "            folders_in_class = os.listdir(class_path)\n",
    "            \n",
    "            for filename in folders_in_class:\n",
    "                labels.append(int(class_folder))\n",
    "                path = os.path.join(class_path, filename)\n",
    "                filenames.append(path)\n",
    "        labels = torch.tensor(labels)\n",
    "        return filenames, labels\n",
    "            \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #open image, apply transforms and return with label\n",
    "        image = Image.open(self.filenames[idx])\n",
    "        \n",
    "#         print(self.filenames[idx])\n",
    "        image = self.transform(image)\n",
    "    \n",
    "        return image, self.labels[idx]\n",
    "\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes): # constructor of NN with its attributes\n",
    "        super(NN, self).__init__() # calling constructor of base class\n",
    "        self.fc1 = nn.Linear(input_size, 120) \n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 36)\n",
    "        self.fc4 = nn.Linear(36,10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x)) \n",
    "        x = F.relu(self.fc2(x)) \n",
    "        x = F.relu(self.fc3(x))\n",
    "        #softmax automatically applied here\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "train_transformer = transforms.Compose([\n",
    "    transforms.Resize(64),\n",
    "    transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))])\n",
    "              \n",
    "batch_size = 64\n",
    "train_data_path = \"SignLanguage\\\\Dataset\"\n",
    "train_loader = DataLoader(dataset = SIGNSDataset(train_data_path, train_transformer), \n",
    "                   batch_size=batch_size, shuffle=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# input_size = len(train_loader.dataset.filenames)\n",
    "input_size = 3*64*64\n",
    "num_classes = 10\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "model = NN(input_size=input_size, num_classes=num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        data = data.to(device=device)\n",
    "\n",
    "        targets = targets.to(device=device)\n",
    "        # The enumerate() method adds a counter to an iterable\n",
    "        #and returns it (the enumerate object)\n",
    "\n",
    "        # Get data to cuda if possible\n",
    "        data = data.to(device=device)\n",
    "        targets = targets.to(device=device)\n",
    "        \n",
    "        # Get to correct shape, 1x28x28->784\n",
    "        # -1 will flatten all outer dimensions into one\n",
    "        #print (data.shape) # [64, 1, 28, 28]\n",
    "        #print (targets.shape) # 64 scalar values.\n",
    "        data = data.reshape(data.shape[0], -1) #[64,1x28x28]=[64, 784]\n",
    "        #print (data.shape) #[64,784]\n",
    "\n",
    "        # forward propagation\n",
    "        scores = model(data) #automatically call the forward method,\n",
    "                                #as model is a callable object\n",
    "        loss = criterion(scores, targets) # compute cost/loss on 64 example\n",
    "        # zero previous gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # back-propagation\n",
    "        loss.backward()\n",
    "\n",
    "        # gradient descent or adam step\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "527e2270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NN(\n",
       "  (fc1): Linear(in_features=12288, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=36, bias=True)\n",
       "  (fc4): Linear(in_features=36, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e092f88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval() # 1. our model deactivates all the layers (eg.batch normalization/dropout)\n",
    "    with torch.no_grad(): #2.  not make computational graph\n",
    "        for x, y in loader:\n",
    "            #print (x.shape)\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "            x = x.reshape(x.shape[0], -1)\n",
    "            #print (y.shape)\n",
    "            \n",
    "            scores = model(x)\n",
    "             \n",
    "            _, predictions = scores.max(1) #. it return max value and its index, 1 mean see column-wise \n",
    "            \n",
    "#             print(predictions)\n",
    "#             print(y)\n",
    "            num_correct += (predictions == y).sum() # compare prediction with y, if equal sum them to count the number of same values\n",
    "            num_samples += predictions.size(0)  #64, get no of samples\n",
    "    print(f\"Got {num_correct} / {num_samples} with accuracy\"\n",
    "      f\" {float(num_correct) / float(num_samples) * 100:.2f}\"\n",
    "            )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a900fe22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: \n",
      "Got 1928 / 2062 with accuracy 93.50\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "print (\"Train accuracy: \")\n",
    "check_accuracy(train_loader, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
